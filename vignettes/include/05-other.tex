\section{object.size() and Strings}

\subsection{Comparison to \code{object.size()}}

\R contains a handy tool for telling you how big an already allocated 
object is, namely the \code{object.size()} function from the \code{utils} 
package.  The functions in this package are essentially an extension of that 
function for unallocated, dense objects, provided your objects are numeric (more 
on this later).

So say we have the vector \code{x <- 1.0}.  This should be using 8 bytes to 
store that \code{1.0} as a double, right?  Well\dots
\begin{lstlisting}[language=rr]
object.size(1.0)
## 48 bytes
\end{lstlisting}

So where is all that extra space coming from?  Simply put, \R objects 
are more than just their data.  They contain a great deal of very useful 
metadata, which is where all the nice abstraction comes from.  Whenever you 
create a vector, \R keeps track of, for example, its length.  If you 
do not appreciate this convenience, go learn \proglang{C} and then get back to 
me.  

For vectors, this overhead is 40 bytes, regardless of the type of data.   
Matrices, unsurprisingly cost more, clocking in at 200 bytes overhead.  It is 
worth noting that this overhead does not scale; it is on a per-object basis.  So 
we don't need 40 bytes for each element of a vector when just 8 would do (in the 
case of double precision values).  We need 40 plus 8 per element:
\begin{lstlisting}[language=rr]
# 2 elements
40+8*2
## [1] 56
object.size(rnorm(2))
## 56 bytes

# 100.000 elements
40+1e5*8
## [1] 800040
object.size(rnorm(1e5))
## 800040 bytes
\end{lstlisting}

The story is slightly more complicated for integer data (and a lot more 
complicated for strings; see the following section).  On my machine (and 
probably yours, but not necessarily), \code{int}s costs 4 bytes.  However, 
\R does some aggressive allocation:
\begin{lstlisting}[language=rr]
object.size(1L:3L)
## 56 bytes
object.size(1L:4L)
## 56 bytes
\end{lstlisting}
Here we see \R allocating more bytes than it needs for integer vectors 
sometimes, choosing to allocate in 16 byte chunks rather than 8 byte chunks.

The \pkg{memuse} package does not adjust for this overhead, because it 
honestly just doesn't matter.  This overhead is really paltry, and when you 
think about all the abstraction it buys you, it's a hell of a bargain.  If you 
have a million R objects stored, you're wasting less than one MiB ($1024^2$ 
bytes); so you would need a billion objects to use just about a GiB ($1024^3$ 
bytes) on overhead.  And if you're doing that kind of silly shit, my advice 
would be to learn how to properly use data structures.

All that said, the main \code{memuse()} (\code{mu()} for short) function
will offer a better version of \code{object.size()}.  In previous 
version, the package overwrote the default functionality, but as of
package version 3.0.0, that is no longer the case. 

The \code{object.size()} function returns an object of class 
\code{object_size}, which is a not-so-useful S3 class provided by core 
\R.  If you instead use \code{memuse()}, then you will get a much more useful
\code{memuse} object.  So revisiting the code above:
\begin{lstlisting}[language=rr]
memuse(rnorm(1e5))
## 781.289 KiB
\end{lstlisting}



\subsection{Strings}

String objects have been avoided up until this point because they are much more 
difficult to describe in general, unless they have a great deal of regularity 
imposed on them.  In \R, strings by default are allocated to use 56 
bytes (not counting overhead), unless they need more.  I'm not sure why this 
value was chosen, but 56 byte strings will allow for the storage of 7 chars 
(like \code{a} but not \code{aa}).  Each char costs 1 byte, so there's some fat 
overhead for the strings here, and almost certainly an additional byte held out 
for the null terminator.  So for example, recall that a vector allocates 40 
bytes of overhead, so the vector string \code{letters} should use $56\times 26 + 
40$ bytes.  We can easily verify that this is the case:
\begin{lstlisting}[language=rr]
56*26+40
## [1] 1496
memuse(letters)
## 1.461 KiB
\end{lstlisting}

If you have a string with more than 7 chars, \R will allocate extra 
space in 8-16 byte blocks.  After the initial 8 byte allocation (7 chars $+$ 
null terminator), if you need more you get an additional 8 bytes (in reality 
this is probably a contiguous 16 byte allocation; I have not bothered to check). 
 Beyond that, storage is allocate in 16 byte blocks for each string.  For 
example:
\begin{lstlisting}[language=rr]
memuse(c(paste(rep("a", 7), collapse=""), "a")) 
## 152 B

  memuse(c(paste(rep("a", 7+1), collapse=""), "a")) 
## 160 B

  memuse(c(paste(rep("a", 7+8+1), collapse=""), "a")) 
## 176 B

  memuse(c(paste(rep("a", 7+8+16+1), collapse=""), "a")) 
## 192 B
\end{lstlisting}

If you have a vector of strings with them of varying lengths, the allocation of 
individual elements is handled on a case-by-case basis.  Consider the 
following:
\begin{lstlisting}[language=rr]
  memuse(c(paste(rep("a", 7+8+16+1), collapse=""), "a")) 
## 192 B
\end{lstlisting}

This object (the vector of 2 elements with first element 
``aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'' and second element ``a'') is using 40 
bytes for the vector, $56+8+16+16$ bytes for the first element, and 56 bytes for 
the second.

For all of these reasons, and given the fact that I almost never (ever) deal 
with character data, I have not bothered to make any attempt to extend, for 
example, \code{howmany()} or \code{howbig()}, to incorporate strings.  Deal 
with it, nerd.
